---
layout: post
title:  "ëª¨ì—¬ë´ìš” ê°•í™”í•™ìˆ²!"
author: ë¯¼ì˜ˆë¦°
categories: [ 8ê¸° ì•„ì¹´ë°ë¯¸ ]
image: assets/images/post/8th-builder/lynnminn/img1.png
published: false
---


ì•ˆë…•í•˜ì„¸ìš”, ëª¨ì—¬ë´ìš” ê°•í™”í•™ìˆ² í”„ë¡œì íŠ¸ ë¹Œë” [ë¯¼ì˜ˆë¦°](www.linkedin.com/in/yerinmin)ì…ë‹ˆë‹¤:)

ì €í¬ëŠ” ê°€ì§œì—°êµ¬ì†Œ ë¦¬ì„œì¹˜íŒ€ì´ê³ , 2022ë…„ 9ì›”ì— ì‹œì‘í•˜ì—¬ 5 ~ 8ê¸°ì— ê±¸ì³ ìŠ¤í„°ë”” ëª¨ì„ì„ ì´ì–´ì˜¤ê³  ìˆìŠµë‹ˆë‹¤. Meta Learning, Model based RL, Graphê¹Œì§€ ì—¬ëŸ¬ ì£¼ì œì— ëŒ€í•´ ê³µë¶€í•˜ê³  ìˆê³ , ê¸°ìˆ˜ë§ˆë‹¤ ë…¼ì˜ë¥¼ í†µí•´ ì¦ê²ê²Œ ê³µë¶€í•  ìˆ˜ ìˆëŠ” ìŠ¤í„°ë”” ì£¼ì œë¥¼ í•¨ê»˜ ì¡ì•„ê°€ê³  ìˆìŠµë‹ˆë‹¤! 
5ê¸°ë¶€í„° í•­ìƒ í•¨ê»˜ í•´ì£¼ì‹œëŠ” (1) ìŠ¤ìŠ¤ë¡œ ë™ê¸°ë¶€ì—¬ë¥¼ ì˜ í•˜ì‹œê³  (2) ì±…ì„ê°ì´ ìˆëŠ” ì¢‹ì€ ë¶„ë“¤ ë•ë¶„ì— 8ê¸°ê¹Œì§€ ì‹œì‘í•˜ê²Œ ë˜ì–´ ì •ë§ ê¸°ì©ë‹ˆë‹¤!

>ğŸ‘‹ 5ê¸° ìŠ¤í„°ë”” : [ë©€í‹°íƒœìŠ¤í¬/ë©”íƒ€ëŸ¬ë‹ ì´ˆì½ê¸°](https://www.notion.so/d28fb9498cc74b1ca7c7f91eba42ec5f?pvs=21)  
>ğŸ‘‹ 6ê¸° ìŠ¤í„°ë”” : [ë©€í‹°íƒœìŠ¤í¬/ë©”íƒ€ëŸ¬ë‹ ì´ˆì½ê¸° & Model based RL](https://www.notion.so/Model-based-RL-a5aac67188164a04aa22fe23478228d1?pvs=21)   
>ğŸ‘‹ multi-task and meta learning [git book ë§í¬](https://pseudo-lab.github.io/Deep-Multi-Task-and-Meta-Learning/intro.html)  
>ğŸ‘‹ 7ê¸° ìŠ¤í„°ë”” : [Graph ì´í•´í•˜ê¸°](https://www.notion.so/Graph-7303268b64f049c89f792ec443de5dae?pvs=21)

ì˜¤ëŠ˜ ê¸€ì—ì„œëŠ” ê·¸ ì¤‘ 8ê¸°ì¸(24ë…„ ìƒë°˜ê¸° ì§„í–‰) 'ëª¨ì—¬ë´ìš” ê°•í™”í•™ìˆ²' ìŠ¤í„°ë””ì— ëŒ€í•´ ì†Œê°œë“œë¦¬ë ¤ê³  í•©ë‹ˆë‹¤!


<br>

## ëª¨ì—¬ë´ìš” ê°•í™”í•™ìˆ² í”„ë¡œì íŠ¸ ì†Œê°œ
ì €í¬ ìŠ¤í„°ë””ëŠ” ì´ë¦„ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ ë‹¤í•¨ê»˜ ëª¨ì—¬ì„œ ê°•í™”í•™ìŠµì— ëŒ€í•œ ì¦ê±°ìš´ ëŒ€í™”ë¥¼ ì´ì–´ê°€ëŠ” ìŠ¤í„°ë””ì…ë‹ˆë‹¤ :) ì €í¬ ë‚´ë¶€ì ìœ¼ë¡œëŠ” ê°•í™”í•™ìŠµ ì·¨ë¯¸ë°˜ì´ë¼ê³ ë„ í•˜ê³  ìˆì–´ìš”!  
ê°•í™”í•™ìŠµì„ í•˜ëŠ” ë¶„ë“¤ë„ ë§ì§€ ì•Šê³ , ì‹œí–‰ì°©ì˜¤ë¥¼ ë‚˜ëˆŒ ìˆ˜ ìˆëŠ” ëª¨ì„ì€ ë”ë”ìš± ì ì–´ìš”! ê·¸ë˜ì„œ ì €í¬ëŠ” ê°•í™”í•™ìŠµ ì—°êµ¬ìë“¤ë¼ë¦¬ ëª¨ì—¬ì„œ í˜ë“¤ì—ˆë˜ ì¼, ë¿Œë“¯í–ˆë˜ ì—°êµ¬ ë“±ì„ ë‚˜ëˆ„ë©° ìˆ˜ë‹¤ë¥¼ ë–¨ ìˆ˜ ìˆëŠ” ìë¦¬ë¥¼ ë§Œë“¤ê³  ìˆìŠµë‹ˆë‹¤ :)

ì•ì „ ìŠ¤í„°ë””ì—ì„œëŠ” íŠ¹ì • ì£¼ì œ(model based rl, meta rl, continual rl)ì— ëŒ€í•´ ê³µë¶€í–ˆë‹¤ë©´ ì´ë²ˆì—ëŠ” ë”ìš± ì·¨ë¯¸ë°˜ì— ë¶€í•©í•˜ë„ë¡ **ì •í•´ì§„ ì»¤ë¦¬í˜ëŸ¼ ì—†ì´ ë§¤ì£¼ 2ê°œì˜ ë…¼ë¬¸ ë¦¬ë·°ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.**  
ê°ì ê·¸ë™ì•ˆ ë³´ê³ ì‹¶ì—ˆìœ¼ë‚˜ ë³¼ ì‹œê°„ì´ ì—†ì—ˆë˜ ë…¼ë¬¸ë“¤ì„ 5ê°œì”© ì·¨í•©í•˜ê³  (ì´ 35ê°œ) ë§¤ì£¼ ëœë¤í•˜ê²Œ ì„ íƒí•´ ë…¼ë¬¸ ë¦¬ë·°ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤. ë•ë¶„ì— offline rl, representation learning ê´€ë ¨ rl í…Œí¬ë‹‰, algorithm, mutitask-learning ë“± êµ‰ì¥íˆ ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ rl ë…¼ë¬¸ì„ ë³¼ ìˆ˜ ìˆì–´ì„œ ë²Œì¨ë¶€í„° ë§ˆìŒì´ ë‘ê·¼ë‘ê·¼ í•˜ë„¤ìš” ã…ã…

*ê°€ì§œì—°êµ¬ì†Œ 8ê¸°ì—ì„œ ì§„í–‰ë˜ëŠ” í”„ë¡œì íŠ¸ëŠ” [ê³„íší‘œ](https://pseudo-lab.com/chanrankim/e4d5b23a28ab43eba97dfd71f8d92bb9)ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”.

<br>

## ë¹Œë” ì†Œê°œ
ì €ëŠ” ê°•í™”í•™ìŠµì„ ë©”ì¸ìœ¼ë¡œ ì—°êµ¬í•˜ê³  ìˆëŠ” [ë¯¼ì˜ˆë¦°](www.linkedin.com/in/yerinmin)ì…ë‹ˆë‹¤.
ê³µë¶€í•´ì•¼ í•  ê²ƒë“¤ì€ ë„ˆë¬´ ë§ì€ë° ì´ì™•ì´ë©´ ì‚¬ëŒë“¤ê³¼ í•¨ê»˜ ì¦ê²ê²Œ í•˜ê³  ì‹¶ì–´ì„œ ê°€ì§œì—°êµ¬ì†Œì— ì°¸ì—¬í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤:)  
ê°€ë” ì˜ì§€ëŠ” ë„˜ì¹˜ì§€ë§Œ ì‹¤í–‰ë ¥ì´ ë¶€ì¡±í•  ë•Œ, ë˜ëŠ” ë‚´ ë¹ ë¥¸ ì‹¤í–‰ë ¥ì„ ëˆ„êµ°ê°€ì™€ ë‚˜ëˆ„ê³  ì‹¶ì„ ë•Œ ìŠ¤í„°ë””ì›ë¶„ë“¤ê³¼ ëª¨ì—¬ì„œ ì„œë¡œ ì‘ì›ë„ í•˜ê³  ë°•ìˆ˜ë„ ì³ì£¼ëŠ” ê·¸ëŸ° ìŠ¤í„°ë””ë¥¼ ì§„í–‰í•˜ê³  ì‹¶ê³  ë˜ ì§„í–‰í•˜ë ¤ê³  ë…¸ë ¥í•˜ê³  ìˆìŠµë‹ˆë‹¤!

ì•„ë˜ëŠ” ì˜ˆì „ ìˆ˜ë„ì½˜ ë°œí‘œ ì´ë¯¸ì§€ì¸ë°, ìë‘ìŠ¤ëŸ¬ì›Œì„œ í•œ ë²ˆ ë„£ì–´ë´¤ìŠµë‹ˆë‹¤!

![img](../assets/images/post/8th-builder/lynnminn/img2.png)

## í”„ë¡œì íŠ¸ ê³„íš
8ê¸° ì‹œì‘ ì „ ì·¨í•©í•œ ë…¼ë¬¸ë“¤ì…ë‹ˆë‹¤.
OTë‚  (3ì›” 5ì¼ í™”ìš”ì¼ ì˜¤í›„ 10ì‹œ) ì‚¬ë‹¤ë¦¬ íƒ€ê¸°ë¥¼ í†µí•´ ë°œí‘œìë¥¼ ì„ ì •í•œ í›„, 2ì£¼ì¹˜ ë…¼ë¬¸ì„ ëœë¤í•˜ê²Œ ì„ íƒí•  ì˜ˆì •ì…ë‹ˆë‹¤ :)  
ë‚´ê°€ ë„£ì–´ ë†“ì€ ì–´ë ¤ìš´ ë…¼ë¬¸ì— ë³¸ì¸ì´ ê±¸ë¦´ ìˆ˜ë„ ìˆì–´ìš”!!!

- [BIRD: Generalizable Backdoor Detection and Removal for Deep Reinforcement Learning](https://openreview.net/pdf?id=l3yxZS3QdT)
- [Learning to Discover Skills through Guidance](https://openreview.net/pdf?id=IUGwUr5_9wY)
- [SMACv2: An Improved Benchmark for Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/pdf/2212.07489.pdf)
- [Contrastive Modules with Temporal Attention for Multi-Task Reinforcement Learning](https://arxiv.org/pdf/2311.01075.pdf)
- [Beyond Uniform Sampling: Offline Reinforcement Learning with Imbalanced Datasets](https://openreview.net/pdf?id=TW99HrZCJU)
- [LEARNING TO ADAPT IN DYNAMIC, REAL-WORLD ENVIRONMENTS THROUGH META-REINFORCEMENT LEARNING](https://openreview.net/pdf?id=HyztsoC5Y7)
- [Solving Dynamic Graph Problems With Multi-Attention Deep RL](https://arxiv.org/pdf/2201.04895.pdf)
- [Offline Actor-Critic Reinforcement Learning Scales to Large Models](https://arxiv.org/pdf/2402.05546.pdf)
- [SafeDreamer](https://arxiv.org/pdf/2307.07176.pdf)
- [Suphx: Mastering Mahjong with Deep Reinforcement Learning](https://arxiv.org/pdf/2003.13590.pdf)
- [Attacking Fake News Detectors via Manipulating News Social Engagement](https://arxiv.org/pdf/2302.07363.pdf)
- [Uncertainty-Aware Reward-based Deep Reinforcement Learning for Intent Analysis of Social Media Information](https://arxiv.org/pdf/2302.10195.pdf)
- [CLARE: A Semi-supervised Community Detection Algorithm](https://arxiv.org/abs/2210.08274)
- [Application of Deep Reinforcement Learning to Payment Fraud](https://arxiv.org/pdf/2112.04236.pdf)
- [Deceptive Path Planning via Reinforcement Learning with Graph Neural Networks](https://arxiv.org/pdf/2402.06552.pdf)
- [Efficient Planning with Latent Diffusion](https://arxiv.org/pdf/2310.00311.pdf)
- [Training Diffusion Models with Reinforcement Learning](https://arxiv.org/pdf/2305.13301.pdf)
- [Reasoning with Latent Diffusion in Offline Reinforcement Learning](https://openreview.net/pdf?id=tGQirjzddO)
- [RLIF: Interactive Imitation Learning as Reinforcement Learning](https://openreview.net/pdf?id=oLLZhbBSOU)
- [Stabilizing Contrastive RL: Techniques for Robotic Goal Reaching from Offline Data](https://openreview.net/pdf?id=4Xsa03f9jR)
- [Project and Probe: Sample-Efficient Adaptation by Interpolating Orthogonal Features](https://openreview.net/pdf?id=rcFkYXmhAR)
- [Mixtures of Experts Unlock Parameter Scaling for Deep RL](https://arxiv.org/pdf/2402.08609.pdf)
- [Retrieval-augmented reinforcement learning](https://arxiv.org/pdf/2202.08417.pdf)
- [Large-scale retrieval for reinforcement learning](https://proceedings.neurips.cc/paper_files/paper/2022/file/7eca17ef54789b0663cab421f2e9dbf5-Supplemental-Conference.pdf)
- [Don't throw away your value model! Making PPO even better via Value-Guided Monte-Carlo Tree Search decoding](https://arxiv.org/pdf/2309.15028.pdf)
- [The primacy bias in deep reinforcement learning](https://arxiv.org/pdf/2205.07802.pdf)
- [REWARD DESIGN WITH LANGUAGE MODELS](https://arxiv.org/pdf/2303.00001.pdf)
- [When Does Self-Supervision Help Graph Convolutional Networks?](https://arxiv.org/pdf/2006.09136.pdf)
- [OFFLINE RL WITH NO OOD ACTIONS: IN-SAMPLE LEARNING VIA IMPLICIT VALUE REGULARIZATION](https://arxiv.org/pdf/2303.15810.pdf)
- [Offline Multi-Agent Reinforcement Learning with Implicit Global-to-Local Value Regularization](https://arxiv.org/pdf/2307.11620.pdf)
- [LEARNING INVARIANT REPRESENTATIONS FOR REINFORCEMENT LEARNING WITHOUT RECONSTRUCTION](https://openreview.net/pdf?id=-2FCwDKRREu)
- [Deep Reinforcement Learning with Plasticity Injection](https://openreview.net/attachment?id=jucDLW6G9l&name=pdf)
- [Explaining Reinforcement Learning with Shapley Values](https://proceedings.mlr.press/v202/beechey23a/beechey23a.pdf)
- [IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures](https://arxiv.org/pdf/1802.01561.pdf)
- [Grandmaster-Level Chess Without Search](https://arxiv.org/pdf/2402.04494.pdf)

<br>

## ì£¼ì°¨ë³„ ëª©í‘œ
ì²« ëª¨ì„ì€ 3ì›” 5ì¼ (í™”) ì˜¤í›„ 10ì‹œì´ë©°, 6ì›” 25ì¼(í™”)ê¹Œì§€ **ë§¤ì£¼ í™”ìš”ì¼ ì˜¤í›„ 10ì‹œ ê°€ì§œì—°êµ¬ì†Œ ë””ìŠ¤ì½”ë“œ**ì—ì„œ ì§„í–‰ë©ë‹ˆë‹¤.
ìì„¸í•œ ì¼ì •ì€ [ê³„íší‘œ](https://pseudo-lab.com/chanrankim/e4d5b23a28ab43eba97dfd71f8d92bb9) ë§¨ í•˜ë‹¨ì„ ì°¸ê³ í•´ì£¼ì„¸ìš”!  
ì¤‘ê°„ & ë§ˆì§€ë§‰ì— ì˜¤í”„ë¼ì¸ ëª¨ì„ë„ ì§„í–‰ë  ì˜ˆì •ì…ë‹ˆë‹¤. ì˜¤í”„ë¼ì¸ ëª¨ì„ ë•ŒëŠ” ëª¨ì—¬ì„œ ìŠ¤í„°ë”” ì§„í–‰ í›„ í•¨ê»˜ ì €ë…ì„ ë¨¹ìœ¼ë©° ê·¼í™©ì„ ë‚˜ëˆ„ëŠ”ë°ìš”, ì²­ê°•ë¶„ë“¤ë„ ì°¸ì—¬í•˜ì…”ì„œ ê°™ì´ ëª¨ì„í•˜ê¸° ë•Œë¬¸ì— **'ëˆ„êµ¬ë“ ' ì˜¨&ì˜¤í”„ë¼ì¸ ì²­ê°•ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!!**


ë§ˆì§€ë§‰ê¹Œì§€ ê¸€ ì½ì–´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤:)  
ìë‘ìŠ¤ëŸ¬ìš´ ì €í¬ íŒ€ì›ë¶„ë“¤ì„ ì†Œê°œë“œë¦¬ë©´ì„œ ë§ˆì¹˜ê² ìŠµë‹ˆë‹¤!

![img](../assets/images/post/8th-builder/lynnminn/img3.png)